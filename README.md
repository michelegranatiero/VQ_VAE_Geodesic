# VQ-VAE with Geodesic Quantization

> **A posteriori vector quantization using geodesic distances in learned latent spaces**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“– Overview

This project revisits the classic VQ-VAE pipeline with a novel twist: instead of jointly learning a discrete latent space, we first train a standard continuous VAE, then perform **a posteriori vector quantization using geodesic distances** (Wasserstein-2) in the latent space, rather than Euclidean ones.

### Key Innovation

Traditional VQ-VAE learns a discrete codebook end-to-end using Euclidean (L2) distance. Our approach:

1. âœ… Train a standard VAE to learn a continuous latent space
2. âœ… Apply K-means clustering with **Wasserstein-2 geodesic distance** 
3. âœ… Build discrete codebook respecting latent manifold geometry
4. âœ… Train PixelCNN autoregressive prior over discrete codes
5. âœ… Compare with traditional end-to-end VQ-VAE

**Why Geodesic?** The Wasserstein-2 metric respects the curvature and uncertainty (Î¼, Ïƒ) of the learned latent manifold, providing geometrically more meaningful quantization than simple Euclidean distance.

## ğŸ¯ Results Highlights

| Metric | VAE + Geodesic | VQ-VAE | Winner |
|--------|----------------|--------|--------|
| **Reconstruction MSE** | 0.0136 | **0.0024** | VQ-VAE (471% better) |
| **Codebook Utilization** | **100%** (256/256) | 85% (218/256) | Geodesic |
| **Dead Codes** | **0** | 38 | Geodesic |
| **Training** | Multi-stage | End-to-end | Different approaches |

**Key Finding**: Geodesic quantization achieves perfect codebook coverage but sacrifices reconstruction quality. The trade-off between geometric fidelity and reconstruction is fundamental to post-hoc vs joint optimization.

## ğŸ—ï¸ Architecture

### VAE + Geodesic Quantization (Our Approach)

```mermaid
graph LR
    A[Input Image] --> B[VAE Encoder]
    B --> C[Î¼, logvar]
    C --> D[Geodesic K-Means]
    D --> E[Discrete Codes]
    E --> F[Codebook Lookup]
    F --> G[VAE Decoder]
    G --> H[Reconstruction]
    
    E --> I[PixelCNN Prior]
    I --> J[New Codes]
    J --> F
```

### VQ-VAE Baseline (End-to-End)

```mermaid
graph LR
    A[Input Image] --> B[Encoder]
    B --> C[Continuous z]
    C --> D[Vector Quantizer]
    D --> E[Discrete Codes]
    E --> F[Decoder]
    F --> G[Reconstruction]
    
    D -.Straight-Through.-> C
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/michelegranatiero/VQ_VAE_Geodesic.git
cd VQ_VAE_Geodesic

# Install dependencies (using uv)
uv sync
```

### Training Pipeline

#### 1. Train VAE (Continuous Latent Space)
```bash
uv run -m vq_vae_geodesic.scripts.train_vae_mnist
```

#### 2. Extract Latents & Apply Geodesic Quantization
```bash
# Extract latent representations (Î¼, logvar) from trained VAE
uv run -m vq_vae_geodesic.scripts.extract_mnist_latents

# Perform K-means clustering with Wasserstein-2 distance
uv run -m vq_vae_geodesic.scripts.quantize_mnist
```

#### 3. Train PixelCNN Autoregressive Prior
```bash
uv run -m vq_vae_geodesic.scripts.train_pixelcnn_mnist
```

#### 4. Train VQ-VAE Baseline (for comparison)
```bash
uv run -m vq_vae_geodesic.scripts.train_vqvae_mnist
```

### Evaluation & Comparison

```bash
# Compare reconstruction quality
uv run -m vq_vae_geodesic.scripts.compare_vae_vs_vqvae

# Compare generation methods (with/without PixelCNN)
uv run -m vq_vae_geodesic.scripts.compare_sampling_methods

# Compare PixelCNN prior vs random sampling
uv run -m vq_vae_geodesic.scripts.compare_pixelcnn_vs_random
```

## ğŸ“Š Visualizations

### Reconstruction Comparison
![Reconstructions](data/recons/comparison/vae_vs_vqvae_reconstructions.png)

*Top to bottom: Original images, VAE+Geodesic reconstructions, VQ-VAE reconstructions*

### Sampling Methods
![Sampling](data/recons/samples/sampling_methods_comparison.png)

*Three approaches: VQ-VAE random, Geodesic+PixelCNN (best), Geodesic random*

### Prior Impact
![Prior](data/recons/samples/pixelcnn_vs_random.png)

*Top: PixelCNN learned prior (realistic), Bottom: Random uniform (noisy)*

## ğŸ“ Project Structure

```
VQ_VAE_Geodesic/
â”œâ”€â”€ src/vq_vae_geodesic/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”‚   â”œâ”€â”€ vae.py              # VAE (encoderâ†’Î¼,logvarâ†’decoder)
â”‚   â”‚   â”‚   â”œâ”€â”€ vqvae.py            # VQ-VAE (encoderâ†’VQâ†’decoder)
â”‚   â”‚   â”‚   â”œâ”€â”€ encoder.py          # Encoder architectures
â”‚   â”‚   â”‚   â”œâ”€â”€ decoder.py          # Decoder architectures
â”‚   â”‚   â”‚   â””â”€â”€ pixelCNN.py         # Autoregressive prior
â”‚   â”‚   â””â”€â”€ quantization/
â”‚   â”‚       â””â”€â”€ geodesic.py         # Geodesic quantizer (Wasserstein-2)
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train_*.py              # Training scripts
â”‚   â”‚   â”œâ”€â”€ compare_*.py            # Comparison scripts
â”‚   â”‚   â””â”€â”€ quantize_mnist.py       # Geodesic quantization
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train.py                # Training loops
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ evaluate.py             # Metrics
â”‚       â””â”€â”€ sample.py               # Sampling utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ checkpoints/                # Saved models
â”‚   â”œâ”€â”€ latents/                    # Extracted latents & codebook
â”‚   â””â”€â”€ recons/                     # Visualizations
â”œâ”€â”€ RESULTS_SUMMARY.md              # Detailed results & analysis
â””â”€â”€ README.md                       # This file
```

## ğŸ”¬ Technical Details

### Geodesic Distance (Wasserstein-2)

Instead of Euclidean L2 distance:
```python
d_euclidean(z1, z2) = ||Î¼1 - Î¼2||Â²
```

We use Wasserstein-2 distance that considers both mean and variance:
```python
d_wasserstein(z1, z2) = ||Î¼1 - Î¼2||Â² + ||Ïƒ1 - Ïƒ2||Â²
```

This respects the probabilistic nature of the VAE latent space and the geometry of the learned manifold.

### Architecture Equivalence

Both VAE and VQ-VAE now use **equivalent architectures** for fair comparison:

**Encoder**: `Conv(1â†’128) â†’ Conv(128â†’256) â†’ Projection`
- VAE: Projects to 32-dim flat vector (Î¼, logvar)
- VQ-VAE: Projects to 4-dim spatial map (7x7)

**Decoder**: `Projection â†’ ConvT(256â†’128) â†’ ConvT(128â†’1)`
- VAE: Takes 32-dim flat vector
- VQ-VAE: Takes 4-dim spatial map (7x7)

**Parameters**: ~1M for both models

### Codebook Configuration

- **Size**: 256 codewords (K=256)
- **Dimension**: 4 per chunk (embedding_dim=4)
- **Grid**: 2x4 = 8 chunks per image
- **Total latent**: 32 dimensions (8 chunks x 4 dim)

## ğŸ“š Key Insights

### âœ… Advantages of Geodesic Quantization

1. **Perfect Codebook Coverage**: 100% utilization vs 85% for VQ-VAE
2. **No Dead Codes**: All 256 codewords are used
3. **Geometric Awareness**: Respects latent manifold curvature
4. **Modularity**: Easy to experiment with different components
5. **Interpretability**: Clear separation of concerns

### âŒ Limitations

1. **Reconstruction Quality**: 471% worse MSE than VQ-VAE
2. **Multi-Stage Training**: More complex pipeline
3. **Computational Cost**: Wasserstein distance expensive
4. **No Joint Optimization**: Cannot fine-tune encoder/decoder for codes

### ğŸ¯ When to Use

**Use Geodesic Quantization** if:
- Codebook coverage is critical
- Latent geometry matters for downstream tasks
- Modularity and interpretability are important

**Use Standard VQ-VAE** if:
- Reconstruction quality is primary metric
- Training simplicity is important
- End-to-end optimization is beneficial

## ğŸ“– References

1. van den Oord et al., "Neural Discrete Representation Learning" (VQ-VAE), NeurIPS 2017
2. Kingma & Welling, "Auto-Encoding Variational Bayes" (VAE), ICLR 2014
3. van den Oord et al., "Pixel Recurrent Neural Networks" (PixelCNN), ICML 2016
4. Optimal Transport theory for Wasserstein distances

## ğŸ“ Academic Context

This is a university project for a Deep Learning course, exploring the impact of non-Euclidean geometry in learned latent spaces. The goal is to understand trade-offs between:
- Post-hoc vs joint optimization
- Geometric fidelity vs reconstruction quality
- Modular vs end-to-end learning

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ‘¤ Author

**Michele Granatiero**
- GitHub: [@michelegranatiero](https://github.com/michelegranatiero)
- Course: Deep Learning (University Project)

## ğŸ™ Acknowledgments

- Course instructors for project guidance
- PyTorch team for deep learning framework
- WandB for experiment tracking

---

For detailed results and analysis, see [RESULTS_SUMMARY.md](RESULTS_SUMMARY.md)
