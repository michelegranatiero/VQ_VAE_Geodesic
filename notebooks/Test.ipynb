{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a29564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import pandas as pd\n",
    "from dlai_project.models.vae import *\n",
    "from dlai_project.train import *\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# reproducibility stuff\n",
    "\n",
    "import random\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(0)\n",
    "\n",
    "torch.cuda.manual_seed(0)\n",
    "# Note that this Deterministic mode can have a performance impact\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378c88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 1, 10])\n",
      "tensor([[[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[-0.0663, -0.0411]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[-0.0663, -0.0411]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0663, -0.0411]],\n",
      "\n",
      "        [[-0.0663, -0.0411]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[-0.0663, -0.0411]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[-0.0419, -0.0673]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]],\n",
      "\n",
      "        [[ 0.0826,  0.0243]],\n",
      "\n",
      "        [[-0.0914,  0.0864]],\n",
      "\n",
      "        [[ 0.0700,  0.0736]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "num_embeddings = 10\n",
    "embedding_dim = 2\n",
    "\n",
    "embeddings = nn.Embedding(num_embeddings, embedding_dim)\n",
    "embeddings.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n",
    "\n",
    "# z: (batch, channel, height, width)\n",
    "z = torch.randn(3, 2, 4, 4)\n",
    "z_flattened = z.permute(0, 2, 3, 1).contiguous()\n",
    "z_flattened = z_flattened.view(-1, embedding_dim)\n",
    "\n",
    "# compute distances\n",
    "distances = (torch.sum(z_flattened**2, dim=1, keepdim=True)\n",
    "                        + torch.sum(embeddings.weight**2, dim=1)\n",
    "                        - 2 * z_flattened @ embeddings.weight.t())\n",
    "encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "encodings = F.one_hot(encoding_indices, num_embeddings).float()\n",
    "quantized = encodings @ embeddings.weight\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlai_project (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
